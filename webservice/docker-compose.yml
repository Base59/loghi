version: '3.1'
services:
  laypa:
    image: 'loghi/docker.laypa'
    command: 'python api/gunicorn_app.py'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    container_name: 'laypa'
    ports:
      - '5000:5000'
    environment:
      LAYPA_MAX_QUEUE_SIZE: 128
      LAYPA_MODEL_BASE_PATH: /home/tim/Documents/laypa-models/NA-LA-CABR-M0003-Turbo/
      LAYPA_OUTPUT_BASE_PATH: /tmp/output/laypa/
      GUNICORN_RUN_HOST: '0.0.0.0:5000'
      GUNICORN_WORKERS: 1
      GUNICORN_THREADS: 1
      GUNICORN_ACCESSLOG: '-'
    volumes:
      - '/home/tim/Documents/laypa-models/:/home/tim/Documents/laypa-models/'
      - '/tmp/output/laypa:/tmp/output/laypa'
    networks:
      - pipeline
    shm_size: 512mb
    restart: always
  loghi-tooling:
    image: 'loghi/docker.loghi-tooling'
    command: '/src/loghi-tooling/loghiwebservice/target/appassembler/bin/LoghiWebserviceApplication server /home/tim/Documents/loghi/webservice/loghi-tooling/configuration.yml'
    container_name: 'loghi-tooling'
    ports:
      - '8080:8080'
      - '8081:8081'
    environment:
      STORAGE_LOCATION: /tmp/upload
      P2PALA_CONFIG_FILE: /doesnotexist
      EXTRACT_BASELINES_MAX_THREADS: 4
      EXTRACT_BASELINES_QUEUE_LENGTH: 64
      CUT_FROM_IMAGE_MAX_THREADS: 4
      CUT_FROM_IMAGE_QUEUE_LENGTH: 64
      LOGHI_HTR_MERGE_PAGE_MAX_THREADS: 4
      LOGHI_HTR_MERGE_PAGE_QUEUE_LENGTH: 64
      RECALCULATE_READING_ORDER_NEW_MAX_THREADS: 4
      RECALCULATE_READING_ORDER_NEW_QUEUE_LENGTH: 64
      SPLIT_PAGE_TEXT_LINE_INTO_WORDS_MAX_THREADS: 4
      SPLIT_PAGE_TEXT_LINE_INTO_WORDS_QUEUE_LENGTH: 64
      DETECT_LANGUAGE_OF_PAGE_XML_MAX_THREADS: 4
      DETECT_LANGUAGE_OF_PAGE_XML_QUEUE_LENGTH: 64
    volumes: 
      - '/home/tim/Documents/loghi/webservice/loghi-tooling/configuration.yml:/home/tim/Documents/loghi/webservice/loghi-tooling/configuration.yml'
      - '/tmp/upload:/tmp/upload'
    networks:
      - pipeline
    shm_size: 512mb
    restart: always
  htr:
    image: 'loghi/docker.htr'
    command: sh -c 'cd api && /usr/local/bin/gunicorn --workers=1 --threads=1 -b :5000 "app:create_app()"'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    container_name: 'htr'
    ports:
      - '5001:5000'
    environment:
      LOGHI_MODEL_PATH: '/home/tim/Documents/loghi-models/NA-HTR-CABR-M0003/'
      LOGHI_BATCH_SIZE: 64
      LOGHI_OUTPUT_PATH: '/tmp/output/loghi-htr'
      LOGHI_MAX_QUEUE_SIZE: 50000
      LOGHI_PATIENCE: 0.5
    volumes:
      - '/home/tim/Documents/loghi-models/:/home/tim/Documents/loghi-models/'
      - '/tmp/output/loghi-htr:/tmp/output/loghi-htr'
    networks:
      - pipeline
    shm_size: 512mb
    restart: always
networks:
  pipeline:
